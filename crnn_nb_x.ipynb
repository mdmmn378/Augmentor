{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "name": "crnn_nb_x.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mdmmn378/Augmentor/blob/master/crnn_nb_x.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gTAyt5yR_tFB",
        "colab_type": "text"
      },
      "source": [
        "# Colab Settings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zXuGzn02orJB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install pytorch_lightning\n",
        "!pip install -U torchvision"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T6s9hUBm5MYl",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WFgxSx78snGB",
        "colab_type": "code",
        "outputId": "fd975897-fdbd-4304-d8f6-0c2ef8350627",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "!wget https://medusa.fit.vutbr.cz/traffic/download/512/"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-09-20 16:42:00--  https://medusa.fit.vutbr.cz/traffic/download/512/\n",
            "Resolving medusa.fit.vutbr.cz (medusa.fit.vutbr.cz)... 147.229.8.49, 2001:67c:1220:808::93e5:831\n",
            "Connecting to medusa.fit.vutbr.cz (medusa.fit.vutbr.cz)|147.229.8.49|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1908808499 (1.8G) [application/octet-stream]\n",
            "Saving to: ‘index.html’\n",
            "\n",
            "index.html          100%[===================>]   1.78G   110MB/s    in 17s     \n",
            "\n",
            "2019-09-20 16:42:18 (109 MB/s) - ‘index.html’ saved [1908808499/1908808499]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-A1EW08ayGgN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mv index.html ./data.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1sjMVq7kyWk3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%capture\n",
        "!unzip data.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Jyr-f60pOjH",
        "colab_type": "text"
      },
      "source": [
        "# Import Modules"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E8mh0RtNpOjL",
        "colab_type": "code",
        "outputId": "7474d5e4-b730-409f-f696-8862d3359d0c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%pdb"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Automatic pdb calling has been turned ON\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V9U5cJC5pOjd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.utils import shuffle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FwHJv8ePpOjq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "import collections\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable # depricated\n",
        "from torch.utils.data import DataLoader,Dataset\n",
        "from torch.nn import functional as F\n",
        "import torchvision.transforms as transforms\n",
        "from torch import optim\n",
        "\n",
        "from IPython.core.debugger import set_trace\n",
        "from IPython.display import clear_output\n",
        "\n",
        "from fastprogress import master_bar, progress_bar\n",
        "\n",
        "import pytorch_lightning as pl\n",
        "from test_tube import Experiment\n",
        "from pytorch_lightning import  Trainer\n",
        "from pytorch_lightning.callbacks import ModelCheckpoint\n",
        "\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BTvFVLEHpOjv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gFsSUZK3pOkc",
        "colab_type": "text"
      },
      "source": [
        "# Utils"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5gc8orBipOkf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class strLabelConverter(object):\n",
        "    def __init__(self, alphabet, ignore_case=True):\n",
        "        self._ignore_case = ignore_case\n",
        "        if self._ignore_case:\n",
        "            alphabet = alphabet.lower()\n",
        "        self.alphabet = alphabet + '~'  # for `-1` index\n",
        "\n",
        "        self.dict = {}\n",
        "        for i, char in enumerate(alphabet):\n",
        "            # NOTE: 0 is reserved for 'blank' required by wrap_ctc\n",
        "            self.dict[char] = i + 1\n",
        "\n",
        "    def encode(self, text):\n",
        "        if isinstance(text, str):\n",
        "            text = [\n",
        "                self.dict[char.lower() if self._ignore_case else char]\n",
        "                for char in text\n",
        "            ]\n",
        "            length = [len(text)]\n",
        "        elif isinstance(text, collections.Iterable):\n",
        "            length = [len(s) for s in text]\n",
        "            text = ''.join(text)\n",
        "            text, _ = self.encode(text)\n",
        "        return (torch.IntTensor(text), torch.IntTensor(length))\n",
        "\n",
        "    def decode(self, t, length, raw=False):\n",
        "#         set_trace()\n",
        "        if length.numel() == 1:\n",
        "            length = length[0]\n",
        "            assert t.numel() == length, \"text with length: {} does not match declared length: {}\".format(t.numel(), length)\n",
        "            if raw:\n",
        "                return ''.join([self.alphabet[i - 1] for i in t])\n",
        "            else:\n",
        "                char_list = []\n",
        "                for i in range(length):\n",
        "                    if t[i] != 0 and (not (i > 0 and t[i - 1] == t[i])):\n",
        "                        char_list.append(self.alphabet[t[i] - 1])\n",
        "                return ''.join(char_list)\n",
        "        else:\n",
        "            # batch mode\n",
        "            assert t.numel() == length.sum(), \"texts with length: {} does not match declared length: {}\".format(t.numel(), length.sum())\n",
        "            texts = []\n",
        "            index = 0\n",
        "            for i in range(length.numel()):\n",
        "                l = length[i]\n",
        "                texts.append(\n",
        "                    self.decode(\n",
        "                        t[index:index + l], torch.IntTensor([l]), raw=raw))\n",
        "                index += l\n",
        "            return texts\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "stN9jza1pOkx",
        "colab_type": "text"
      },
      "source": [
        "# Augmentation and Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HLF28f3CpOk7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# df = pd.read_csv('./data/trainVal.csv')\n",
        "# img = Image.open(os.path.join('data',df['image_path'][0]))\n",
        "# img"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P1lycvwKpOlA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DataSet(Dataset):\n",
        "    def __init__(self,root='./',dfn='trainVal.csv',img_height=32,img_width=96,alphabet='0123456789abcdefghijklmnopqrstuvwxyz'):\n",
        "        self.root  = root\n",
        "        self.df = pd.read_csv(os.path.join(root,dfn))\n",
        "        self.tensorize = transforms.ToTensor()\n",
        "        self.resize = transforms.Resize((img_height,img_width))\n",
        "        self.alphabet = alphabet\n",
        "        self.converter = strLabelConverter(self.alphabet)\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "    def __getitem__(self,index):\n",
        "        loc = self.df['image_path'][index]\n",
        "        label = self.df['lp'][index]\n",
        "        img = Image.open(os.path.join(self.root,loc)).convert('L')\n",
        "        img = self.resize(img)\n",
        "        img = self.tensorize(img)\n",
        "        label = self.converter.encode(label)\n",
        "        return img,label\n",
        "        \n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yz6Wo9hEpOlM",
        "colab_type": "text"
      },
      "source": [
        "# Data Handler"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BHU3XS87pOlO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def spliter(dataset,ratio):\n",
        "    ln = len(dataset)\n",
        "    ln1 = int(ln*ratio)\n",
        "    ln2 = ln-ln1\n",
        "    split1,split2 = torch.utils.data.random_split(dataset,[ln1,ln2])\n",
        "    return split1,split2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qEDv973KpOlg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dataset = DataSet()\n",
        "train_dataset,val_dataset = spliter(train_dataset,0.8)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "14b2NF-apOlv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def collate_fn(batch):\n",
        "    batch_size = len(batch)\n",
        "    images = [i[0] for i in batch]\n",
        "    images = torch.stack(images)\n",
        "    \n",
        "    targets  = [i[1][0] for i in batch]\n",
        "    targets = torch.cat([*targets],dim=0).cuda()\n",
        "    \n",
        "    target_lens = torch.cuda.IntTensor([len(i[1][0]) for i in batch])\n",
        "    return images,batch_size,targets,target_lens\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LGU7EwyJpOl6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_loader = DataLoader(train_dataset,batch_size=32,shuffle=True,collate_fn=collate_fn)\n",
        "val_loader = DataLoader(val_dataset,batch_size=32,shuffle=True,collate_fn=collate_fn)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nYV2unpcpOmB",
        "colab_type": "code",
        "outputId": "4216cb2a-8860-425b-c6d1-71c2296c426f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# # # %%capture\n",
        "for info in val_loader:\n",
        "    print(info)\n",
        "    break"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(tensor([[[[0.0863, 0.0824, 0.0941,  ..., 0.1725, 0.1922, 0.2118],\n",
            "          [0.0784, 0.0745, 0.0745,  ..., 0.2353, 0.2588, 0.2784],\n",
            "          [0.1059, 0.0902, 0.0784,  ..., 0.2706, 0.2863, 0.3059],\n",
            "          ...,\n",
            "          [0.0588, 0.0588, 0.0588,  ..., 0.0745, 0.0745, 0.0784],\n",
            "          [0.0667, 0.0667, 0.0667,  ..., 0.0667, 0.0706, 0.0706],\n",
            "          [0.0667, 0.0667, 0.0667,  ..., 0.0627, 0.0667, 0.0667]]],\n",
            "\n",
            "\n",
            "        [[[0.2235, 0.2235, 0.2314,  ..., 0.2745, 0.2745, 0.2745],\n",
            "          [0.2118, 0.2196, 0.2275,  ..., 0.2627, 0.2667, 0.2627],\n",
            "          [0.2039, 0.2118, 0.2196,  ..., 0.2549, 0.2549, 0.2549],\n",
            "          ...,\n",
            "          [0.1569, 0.1569, 0.1569,  ..., 0.1255, 0.1216, 0.1216],\n",
            "          [0.1490, 0.1529, 0.1529,  ..., 0.1137, 0.1137, 0.1176],\n",
            "          [0.1412, 0.1412, 0.1451,  ..., 0.1098, 0.1137, 0.1176]]],\n",
            "\n",
            "\n",
            "        [[[0.8706, 0.8667, 0.8667,  ..., 0.8431, 0.8706, 0.8863],\n",
            "          [0.8627, 0.8627, 0.8588,  ..., 0.8000, 0.8039, 0.7961],\n",
            "          [0.8431, 0.8392, 0.8353,  ..., 0.6784, 0.7176, 0.7373],\n",
            "          ...,\n",
            "          [0.1137, 0.1098, 0.1059,  ..., 0.1216, 0.1255, 0.1333],\n",
            "          [0.1216, 0.1098, 0.1059,  ..., 0.1176, 0.1176, 0.1333],\n",
            "          [0.1255, 0.1176, 0.1176,  ..., 0.1216, 0.1294, 0.1451]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0.4118, 0.4039, 0.4000,  ..., 0.4980, 0.5020, 0.5020],\n",
            "          [0.4824, 0.4784, 0.4745,  ..., 0.5020, 0.5020, 0.4941],\n",
            "          [0.4824, 0.4706, 0.4706,  ..., 0.4902, 0.4941, 0.4902],\n",
            "          ...,\n",
            "          [0.1294, 0.1294, 0.1294,  ..., 0.1059, 0.1098, 0.1176],\n",
            "          [0.1216, 0.1216, 0.1255,  ..., 0.1137, 0.1216, 0.1176],\n",
            "          [0.1137, 0.1137, 0.1137,  ..., 0.1412, 0.1451, 0.1451]]],\n",
            "\n",
            "\n",
            "        [[[0.2863, 0.2863, 0.2902,  ..., 0.2902, 0.2824, 0.2784],\n",
            "          [0.2627, 0.2588, 0.2627,  ..., 0.2627, 0.2549, 0.2510],\n",
            "          [0.2000, 0.2000, 0.2000,  ..., 0.2078, 0.2039, 0.2000],\n",
            "          ...,\n",
            "          [0.0353, 0.0353, 0.0314,  ..., 0.0353, 0.0314, 0.0353],\n",
            "          [0.0314, 0.0314, 0.0314,  ..., 0.0353, 0.0353, 0.0314],\n",
            "          [0.0314, 0.0314, 0.0314,  ..., 0.0392, 0.0392, 0.0353]]],\n",
            "\n",
            "\n",
            "        [[[0.4510, 0.4471, 0.4431,  ..., 0.4314, 0.4314, 0.4353],\n",
            "          [0.4471, 0.4392, 0.4431,  ..., 0.4392, 0.4392, 0.4431],\n",
            "          [0.4196, 0.4157, 0.4275,  ..., 0.4471, 0.4471, 0.4510],\n",
            "          ...,\n",
            "          [0.0549, 0.0549, 0.0549,  ..., 0.1059, 0.1059, 0.1020],\n",
            "          [0.0510, 0.0510, 0.0510,  ..., 0.1176, 0.1176, 0.1137],\n",
            "          [0.0588, 0.0588, 0.0588,  ..., 0.1216, 0.1216, 0.1176]]]]), 32, tensor([ 9, 12,  2,  3, 10,  6,  4,  8, 12,  9,  1,  1,  5, 10,  2, 12, 15,  6,\n",
            "        10,  1,  9, 24, 14, 21,  8,  5,  6,  2, 12, 10,  1,  1,  8,  3,  4, 12,\n",
            "         9,  7,  9,  7,  8,  3,  4,  2,  2, 20, 14, 21,  3, 12,  6,  2,  3,  5,\n",
            "         7,  6, 11, 13,  7,  7,  4,  5,  2, 12, 10,  1, 10,  4,  8,  5, 12,  5,\n",
            "         6,  1,  1,  6,  2, 12, 21,  2,  1,  7,  2, 12, 36, 29,  3,  9,  9,  3,\n",
            "         2, 29, 20,  7,  8,  7,  5, 10, 11,  1,  8, 10,  8,  1,  6, 12,  5,  3,\n",
            "         2,  6, 10,  5, 15, 10, 10,  3,  3,  9,  7, 12,  6,  3,  3,  5,  3,  8,\n",
            "        12,  7,  1, 10,  7,  6,  2, 12, 16,  4,  8,  6,  8,  3, 12,  7,  6,  2,\n",
            "         4,  5,  9, 12, 10,  3,  1,  6,  8,  2, 12, 22,  2,  3,  8,  4,  2, 12,\n",
            "        19,  1,  6,  5,  8,  6, 15,  8, 10,  2,  6,  3,  6, 12,  7,  6,  7,  6,\n",
            "         6,  5, 11, 16, 10, 10,  9,  9, 10, 12,  2,  4,  4, 10,  2,  5, 12,  4,\n",
            "         9,  7, 10,  1,  5, 12,  5,  5,  4,  4,  8,  5, 12,  4,  1,  1,  8, 10,\n",
            "         3, 12, 10,  7,  3,  1,  5], device='cuda:0', dtype=torch.int32), tensor([7, 7, 7, 6, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,\n",
            "        7, 7, 7, 7, 7, 7, 7, 7], device='cuda:0', dtype=torch.int32))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7T0mSZIRpOmL",
        "colab_type": "text"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aukLlhDPpOmN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BidirectionalLSTM(nn.Module):\n",
        "\n",
        "    def __init__(self, nIn, nHidden, nOut):\n",
        "        super(BidirectionalLSTM, self).__init__()\n",
        "\n",
        "        self.rnn = nn.LSTM(nIn, nHidden, bidirectional=True)\n",
        "        self.embedding = nn.Linear(nHidden * 2, nOut)\n",
        "\n",
        "    def forward(self, input):\n",
        "#         set_trace()\n",
        "        recurrent, _ = self.rnn(input)\n",
        "        T, b, h = recurrent.size()\n",
        "        t_rec = recurrent.view(T * b, h)\n",
        "\n",
        "        output = self.embedding(t_rec)  # [T * b, nOut]\n",
        "        output = output.view(T, b, -1)\n",
        "\n",
        "        return output\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PcYJ9N9DpOmS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "class CRNN(nn.Module):\n",
        "\n",
        "    def __init__(self, imgH, nc, nclass, nh, n_rnn=2, leakyRelu=False):\n",
        "        super(CRNN, self).__init__()\n",
        "        assert imgH % 16 == 0, 'imgH has to be a multiple of 16'\n",
        "\n",
        "        ks = [3, 3, 3, 3, 3, 3, 2]\n",
        "        ps = [1, 1, 1, 1, 1, 1, 0]\n",
        "        ss = [1, 1, 1, 1, 1, 1, 1]\n",
        "        nm = [64, 128, 256, 256, 512, 512, 512]\n",
        "\n",
        "        cnn = nn.Sequential()\n",
        "\n",
        "        def convRelu(i, batchNormalization=False):\n",
        "            nIn = nc if i == 0 else nm[i - 1]\n",
        "            nOut = nm[i]\n",
        "            cnn.add_module('conv{0}'.format(i),\n",
        "                           nn.Conv2d(nIn, nOut, ks[i], ss[i], ps[i]))\n",
        "            if batchNormalization:\n",
        "                cnn.add_module('batchnorm{0}'.format(i), nn.BatchNorm2d(nOut))\n",
        "            if leakyRelu:\n",
        "                cnn.add_module('relu{0}'.format(i),\n",
        "                               nn.LeakyReLU(0.2, inplace=True))\n",
        "            else:\n",
        "                cnn.add_module('relu{0}'.format(i), nn.ReLU(True))\n",
        "\n",
        "        convRelu(0)\n",
        "        cnn.add_module('pooling{0}'.format(0), nn.MaxPool2d(2, 2))  # 64x16x64\n",
        "        convRelu(1)\n",
        "        cnn.add_module('pooling{0}'.format(1), nn.MaxPool2d(2, 2))  # 128x8x32\n",
        "        convRelu(2, True)\n",
        "        convRelu(3)\n",
        "        cnn.add_module('pooling{0}'.format(2),\n",
        "                       nn.MaxPool2d((2, 2), (2, 1), (0, 1)))  # 256x4x16\n",
        "        convRelu(4, True)\n",
        "        convRelu(5)\n",
        "        cnn.add_module('pooling{0}'.format(3),\n",
        "                       nn.MaxPool2d((2, 2), (2, 1), (0, 1)))  # 512x2x16\n",
        "        convRelu(6, True)  # 512x1x16\n",
        "\n",
        "        self.cnn = cnn\n",
        "        self.rnn = nn.Sequential(\n",
        "            BidirectionalLSTM(512, nh, nh),\n",
        "            BidirectionalLSTM(nh, nh, nclass))\n",
        "\n",
        "    def forward(self, input):\n",
        "#         set_trace()\n",
        "        conv = self.cnn(input)\n",
        "        b, c, h, w = conv.size()\n",
        "        assert h == 1, \"the height of conv must be 1\"\n",
        "        conv = conv.squeeze(2)\n",
        "        conv = conv.permute(2, 0, 1)  # [w, b, c]\n",
        "\n",
        "        # rnn features\n",
        "        output = self.rnn(conv)\n",
        "\n",
        "        return output\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bZA2dHfIpOmc",
        "colab_type": "text"
      },
      "source": [
        "# Experimental Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3EFM0JlPpOme",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class NumberPlateDetector(pl.LightningModule):\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.model = CRNN(32, 1, 37, 256)\n",
        "#         for param in self.nn_model.parameters():\n",
        "#             param.requires_grad = False\n",
        "    def forward(self, x):\n",
        "        x = self.model(x)\n",
        "        return x\n",
        "\n",
        "    def training_step(self, batch, batch_nb):\n",
        "        x, batch,y,ys = batch\n",
        "        y_hat = self.forward(x)\n",
        "#         set_trace()\n",
        "        xs = torch.empty([y_hat.shape[1]],dtype=torch.int,device='cuda')\n",
        "        xs.fill_(y_hat.shape[0])\n",
        "        criterion = torch.nn.CTCLoss().to('cuda')\n",
        "        loss = criterion(y_hat.to('cpu'),y.to('cpu'),xs.to('cpu'),ys.to('cpu'))\n",
        "        return {'loss': loss}\n",
        "\n",
        "#     def validation_step(self, batch, batch_nb):\n",
        "#         x, y = batch\n",
        "#         y_hat = self.forward(x)\n",
        "#         return {'val_loss': F.cross_entropy(y_hat, y)}\n",
        "\n",
        "#     def validation_end(self, outputs):\n",
        "#         avg_loss = torch.stack([x['val_loss'] for x in outputs]).mean()\n",
        "#         return {'avg_val_loss':avg_loss}\n",
        "\n",
        "#     def configure_optimizers(self):\n",
        "#         return [torch.optim.Adam(self.parameters(), lr=0.02),torch.optim.Adam(self.parameters(), lr=0.02)]\n",
        "    \n",
        "#     def on_batch_start(self):\n",
        "#         do something when the batch starts\n",
        "#      def on_tng_metrics(self, metrics):\n",
        "#         pass\n",
        "#     def update_tng_log_metrics(self, logs):\n",
        "#         return logs\n",
        "\n",
        "\n",
        "#     def optimizer_step(self, current_epoch, batch_nb, optimizer, optimizer_i):\n",
        "#         set_trace()\n",
        "#         optimizer.step()\n",
        "#         optimizer.zero_grad()\n",
        "#         if optimizer_i == 0:\n",
        "#             if batch_nb % 2 == 0 :\n",
        "#                 optimizer.step()\n",
        "#                 optimizer.zero_grad()\n",
        "\n",
        "#         if optimizer_i == 1:\n",
        "#             if batch_nb % 4 == 0 :\n",
        "#                 optimizer.step()\n",
        "#                 optimizer.zero_grad()  \n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        optimizer = optim.Adam(self.parameters(),lr=0.5e-2)\n",
        "        scheduler = optim.lr_scheduler.CyclicLR(optimizer,max_lr=0.5e-2,base_lr=5e-4,cycle_momentum=False)\n",
        "#         return [optimizer], [scheduler]                \n",
        "        return optimizer\n",
        "\n",
        "    @pl.data_loader\n",
        "    def tng_dataloader(self):\n",
        "        return train_loader\n",
        "\n",
        "#     @pl.data_loader\n",
        "#     def val_dataloader(self):\n",
        "#         return val_loader\n",
        "\n",
        "#     @pl.data_loader\n",
        "#     def test_dataloader(self):\n",
        "#         return DataLoader(MNIST(os.getcwd(), train=False, download=True, transform=transforms.ToTensor()), batch_size=64)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ID1-BwbppOmi",
        "colab_type": "text"
      },
      "source": [
        "# Train and Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6wDNa08PpOmk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = NumberPlateDetector()\n",
        "exp = Experiment(save_dir='./weights')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4zc_OIZ_pOms",
        "colab_type": "code",
        "outputId": "da8a5980-dca3-48ac-ffbf-72fc89cefd51",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "trainer = Trainer(max_nb_epochs=300,experiment=exp,show_progress_bar=True,gpus=[0],checkpoint_callback=None)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "VISIBLE GPUS: '0'\n",
            "gpu available: True, used: True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iImnXEVHpOmx",
        "colab_type": "code",
        "outputId": "e2d1f57b-a6ca-4047-b921-2afad9965072",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 885
        }
      },
      "source": [
        "model.train()\n",
        "#trainer.optimizers[0].lr = 0.0001\n",
        "trainer.fit(model)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 1/4559 [00:00<06:13, 12.22it/s, batch_nb=0, epoch=2, gpu=0, loss=0.016, v_nb=0]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "                     Name               Type   Params\n",
            "0                   model               CRNN  8331301\n",
            "1               model.cnn         Sequential  5551360\n",
            "2         model.cnn.conv0             Conv2d      640\n",
            "3         model.cnn.relu0               ReLU        0\n",
            "4      model.cnn.pooling0          MaxPool2d        0\n",
            "5         model.cnn.conv1             Conv2d    73856\n",
            "6         model.cnn.relu1               ReLU        0\n",
            "7      model.cnn.pooling1          MaxPool2d        0\n",
            "8         model.cnn.conv2             Conv2d   295168\n",
            "9    model.cnn.batchnorm2        BatchNorm2d      512\n",
            "10        model.cnn.relu2               ReLU        0\n",
            "11        model.cnn.conv3             Conv2d   590080\n",
            "12        model.cnn.relu3               ReLU        0\n",
            "13     model.cnn.pooling2          MaxPool2d        0\n",
            "14        model.cnn.conv4             Conv2d  1180160\n",
            "15   model.cnn.batchnorm4        BatchNorm2d     1024\n",
            "16        model.cnn.relu4               ReLU        0\n",
            "17        model.cnn.conv5             Conv2d  2359808\n",
            "18        model.cnn.relu5               ReLU        0\n",
            "19     model.cnn.pooling3          MaxPool2d        0\n",
            "20        model.cnn.conv6             Conv2d  1049088\n",
            "21   model.cnn.batchnorm6        BatchNorm2d     1024\n",
            "22        model.cnn.relu6               ReLU        0\n",
            "23              model.rnn         Sequential  2779941\n",
            "24            model.rnn.0  BidirectionalLSTM  1708288\n",
            "25        model.rnn.0.rnn               LSTM  1576960\n",
            "26  model.rnn.0.embedding             Linear   131328\n",
            "27            model.rnn.1  BidirectionalLSTM  1071653\n",
            "28        model.rnn.1.rnn               LSTM  1052672\n",
            "29  model.rnn.1.embedding             Linear    18981\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 24%|██▎       | 1076/4559 [01:24<04:31, 12.84it/s, batch_nb=1075, epoch=3, gpu=0, loss=0.018, v_nb=0]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-50-1bd724cc0464>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0001\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pytorch_lightning/models/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model)\u001b[0m\n\u001b[1;32m    596\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msingle_gpu\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__single_gpu_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    599\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m         \u001b[0;31m# ON CPU\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pytorch_lightning/models/trainer.py\u001b[0m in \u001b[0;36m__single_gpu_train\u001b[0;34m(self, model)\u001b[0m\n\u001b[1;32m    644\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    645\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 646\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__run_pretrain_routine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    647\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    648\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__dp_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pytorch_lightning/models/trainer.py\u001b[0m in \u001b[0;36m__run_pretrain_routine\u001b[0;34m(self, model)\u001b[0m\n\u001b[1;32m    843\u001b[0m         \u001b[0;31m# CORE TRAINING LOOP\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    844\u001b[0m         \u001b[0;31m# ---------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 845\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    846\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    847\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pytorch_lightning/models/trainer.py\u001b[0m in \u001b[0;36m__train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    867\u001b[0m             \u001b[0;31m# RUN TNG EPOCH\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m             \u001b[0;31m# -----------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 869\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_tng_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    870\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    871\u001b[0m             \u001b[0;31m# update LR schedulers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pytorch_lightning/models/trainer.py\u001b[0m in \u001b[0;36mrun_tng_epoch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    891\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    892\u001b[0m         \u001b[0;31m# run epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 893\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch_nb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_batch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtng_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    894\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_nb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_nb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    895\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_step\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 346\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 256\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-24-8b031d93d465>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'L'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensorize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, pic)\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mConverted\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \"\"\"\n\u001b[0;32m---> 92\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mto_tensor\u001b[0;34m(pic)\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mByteTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s9FxWqb7pOnY",
        "colab_type": "text"
      },
      "source": [
        "# Visualization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2732SD4EpOne",
        "colab_type": "text"
      },
      "source": [
        "# Saving Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hrVflFskpOng",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.save(model.state_dict(), './model.ckpt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BrcttLpmpOnk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model.load_state_dict(torch.load('./model.ckpt'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wjoVQJw0pOnz",
        "colab_type": "text"
      },
      "source": [
        "# Other Experiments"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xH2GytoXpOn2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img = Image.open('./s01_l01/2_1.png').convert('L')\n",
        "img = transforms.Resize((32,96))(img)\n",
        "img = transforms.ToTensor()(img)\n",
        "img = img.reshape(1,*img.shape).to('cuda')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9WSYvxEdpOoA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.eval()\n",
        "preds = model(img)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4MHnH79BpOoF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "xs = torch.empty([preds.shape[1]],dtype=torch.int).to('cuda')\n",
        "xs.fill_(preds.shape[0])\n",
        "_, preds = preds.max(2)\n",
        "preds = preds.transpose(1, 0).contiguous().view(-1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-P4-kgiGpOoJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "converter = strLabelConverter('0123456789abcdefghijklmnopqrstuvwxyz')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zyy3BmoCpOoT",
        "colab_type": "code",
        "outputId": "438857f8-2a46-411f-f21e-096737ee6921",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "converter.decode(preds,xs)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'7c2498'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lo-sd0VR2ju1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}